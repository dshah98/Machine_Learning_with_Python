{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Classification Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy allows us to work with array.\n",
    "import numpy as np\n",
    "\n",
    "# Maptplotlib which allows us to plot some chart.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pandas allows us to not only import the datasets but also create the matrix of features(independent) and \n",
    "# dependent variable.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x1 = dataset.iloc[:, :-1].values\n",
    "y1 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x1_train = sc.fit_transform(x1_train)\n",
    "x1_test = sc.transform(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the Logistic Regression on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n",
      "Accuracy Score of Logistic Regression is 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y1_pred = classifier.predict(x1_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm1 = confusion_matrix(y1_test, y1_pred)\n",
    "print(cm1)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of Logistic Regression is\",accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x2 = dataset.iloc[:, :-1].values\n",
    "y2 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x2_train = sc.fit_transform(x2_train)\n",
    "x2_test = sc.transform(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the KNN Model on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n",
      "Accuracy Score of KNN Model is 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y2_pred = classifier.predict(x2_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "print(cm2)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of KNN Model is\",accuracy_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Support Vector Machine SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x3 = dataset.iloc[:, :-1].values\n",
    "y3 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x3_train = sc.fit_transform(x3_train)\n",
    "x3_test = sc.transform(x3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the SVM on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  5  59]]\n",
      "Accuracy Score of SVM is 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y3_pred = classifier.predict(x3_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm3 = confusion_matrix(y3_test, y3_pred)\n",
    "print(cm3)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of SVM is\",accuracy_score(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Kernel Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x4 = dataset.iloc[:, :-1].values\n",
    "y4 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x4_train = sc.fit_transform(x4_train)\n",
    "x4_test = sc.transform(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the Kernel SVM on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x4_train, y4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  3  61]]\n",
      "Accuracy Score of Kernel SVM is 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y4_pred = classifier.predict(x4_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm4 = confusion_matrix(y4_test, y4_pred)\n",
    "print(cm4)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of Kernel SVM is\",accuracy_score(y4_test, y4_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x5 = dataset.iloc[:, :-1].values\n",
    "y5 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x5_train, x5_test, y5_train, y5_test = train_test_split(x5, y5, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x5_train = sc.fit_transform(x5_train)\n",
    "x5_test = sc.transform(x5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the Naive Bayes on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x5_train, y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  8]\n",
      " [ 2 62]]\n",
      "Accuracy Score of Naive Bayes is 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y5_pred = classifier.predict(x5_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm5 = confusion_matrix(y5_test, y5_pred)\n",
    "print(cm5)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of Naive Bayes is\",accuracy_score(y5_test, y5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x6 = dataset.iloc[:, :-1].values\n",
    "y6 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x6_train, x6_test, y6_train, y6_test = train_test_split(x6, y6, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y6_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x6_train = sc.fit_transform(x6_train)\n",
    "x6_test = sc.transform(x6_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x6_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the Random Forest Classifier on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x6_train, y6_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  3  61]]\n",
      "Accuracy Score of Decision Tree Classifier is 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y6_pred = classifier.predict(x6_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm6 = confusion_matrix(y6_test, y6_pred)\n",
    "print(cm6)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of Decision Tree Classifier is\",accuracy_score(y6_test, y6_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable usally in the first columns of dataset and dependent variable usally in the last columns of the data sets.\n",
    "- X is Independent Variable.\n",
    "- Y is Dependent Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Breast_Cancer.csv')\n",
    "x7 = dataset.iloc[:, :-1].values\n",
    "y7 = dataset.iloc[:, -1].values\n",
    "\n",
    "print(x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "**Splitting the dataset into the Training set and Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 142932       7       6 ...       9      10       2]\n",
      " [1120559       8       3 ...       8       9       8]\n",
      " [1254538       8      10 ...      10      10       1]\n",
      " ...\n",
      " [1214092       1       1 ...       1       1       1]\n",
      " [1303489       3       1 ...       2       1       1]\n",
      " [ 378275      10       9 ...       7       7       1]]\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividing training and test set.\n",
    "# The best ratio is 80 - 20 for trainging and testing respectively.\n",
    "x7_train, x7_test, y7_train, y7_test = train_test_split(x7, y7, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(x7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 2 2 2 4 2 2 4 4 2 4 2 2 4 4 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 4 2 4\n",
      " 2 2 2 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4\n",
      " 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 4 2 2 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2\n",
      " 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 4 4 2 4 2 2 2 4 2 2 2 4 4 2 4 2 2 4 2 2 2 2\n",
      " 2 2 2 4 4 4 4 2 4 2 4 2 4 4 4 2 2 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 2 2 2 4 4 4 4 2 2 4 2 4 2 4 2 2 2 2 4 2\n",
      " 4 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 4 2 2 4\n",
      " 2 2 2 2 4 4 2 2 2 2 4 2 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 4 4 4 2 2 2 2 2 2 2\n",
      " 2 4 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 2\n",
      " 2 2 4 2 2 2 4 2 2 4 4 4 2 4 4 4 2 2 2 4 2 4 2 2 4 2 4 4 4 2 2 2 4 2 4 4 4\n",
      " 2 2 2 4 2 4 2 2 2 2 4 4 2 2 2 4 4 2 2 4 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 2\n",
      " 4 2 2 2 2 4 4 2 2 4 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 2 4 4 2 2 2 2 4 2 2 2 2\n",
      " 4 2 4 2 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 4 4 4 4 2 4 4 2 4 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 4 2 4 4 4 2 2 4 4 2 2 2 2 2 2 4 2 2 4 2 2 4 2 2 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y7_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fitting and Transforming\n",
    "x7_train = sc.fit_transform(x7_train)\n",
    "x7_test = sc.transform(x7_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38219432  0.91903747  0.9407658  ...  2.22576767  2.27129602\n",
      "   0.24623928]\n",
      " [ 0.03390689  1.27578287 -0.04290763 ...  1.82407819  1.94996317\n",
      "   3.74830911]\n",
      " [ 0.22797663  1.27578287  2.25233038 ...  2.62745714  2.27129602\n",
      "  -0.33743902]\n",
      " ...\n",
      " [ 0.16939025 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.29888258 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-1.04129794  1.98927367  1.92443923 ...  1.42238871  1.30729749\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11037076 -1.22143494 -0.69868992 ... -0.98774815 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.08526811 -0.50794414 -0.69868992 ... -0.58605867 -0.62069958\n",
      "  -0.33743902]\n",
      " [-0.56596836  0.20554667  0.61287466 ...  0.21732028  0.02196611\n",
      "  -0.33743902]\n",
      " ...\n",
      " [-0.48116108  0.20554667 -0.69868992 ... -0.18436919 -0.62069958\n",
      "   0.24623928]\n",
      " [ 0.05794779 -0.86468954 -0.37079877 ...  1.42238871 -0.62069958\n",
      "  -0.33743902]\n",
      " [ 0.09172701 -0.86468954 -0.69868992 ... -0.18436919 -0.62069958\n",
      "  -0.33743902]]\n"
     ]
    }
   ],
   "source": [
    "print(x7_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "**Training the Random Forest Classifier on the Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "\n",
    "# Fitting\n",
    "classifier.fit(x7_train, y7_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  6  58]]\n",
      "Accuracy Score of Random Forest Classifier is 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "# Importing Package\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predicting\n",
    "y7_pred = classifier.predict(x7_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm7 = confusion_matrix(y7_test, y7_pred)\n",
    "print(cm7)\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score of Random Forest Classifier is\",accuracy_score(y7_test, y7_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is 0.9473684210526315\n",
      "Accuracy Score of KNN Model is 0.9473684210526315\n",
      "Accuracy Score of SVM is 0.9415204678362573\n",
      "Accuracy Score of Kernel SVM is 0.9532163742690059\n",
      "Accuracy Score of Naive Bayes is 0.9415204678362573\n",
      "Accuracy Score of Decision Tree Classifier is 0.9590643274853801\n",
      "Accuracy Score of Random Forest Classifier is 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Logistic Regression is\",accuracy_score(y1_test, y1_pred))\n",
    "print(\"Accuracy Score of KNN Model is\",accuracy_score(y2_test, y2_pred))\n",
    "print(\"Accuracy Score of SVM is\",accuracy_score(y3_test, y3_pred))\n",
    "print(\"Accuracy Score of Kernel SVM is\",accuracy_score(y4_test, y4_pred))\n",
    "print(\"Accuracy Score of Naive Bayes is\",accuracy_score(y5_test, y5_pred))\n",
    "print(\"Accuracy Score of Decision Tree Classifier is\",accuracy_score(y6_test, y6_pred))\n",
    "print(\"Accuracy Score of Random Forest Classifier is\",accuracy_score(y7_test, y7_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So the Best Model is Decision Tree Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
